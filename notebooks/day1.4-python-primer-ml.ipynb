{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Primer: starting ML\n",
    "\n",
    "## <div style=\"color: #db366d\"> Day 1.4 </div>\n",
    "\n",
    "Python has become the de facto language for ML. It is almost expected that you are fluent with Python if you claim to be working on ML.\n",
    "\n",
    "We have seen how to work with data. Once we're happy with how our data looks, we can now proceed to do the \"interesting\" stuff.\n",
    "\n",
    "As with data processing, the ML community has provided Python with some very powerful open-source libs, e.g.,\n",
    "\n",
    "<img src=\"../images/sklearn-logo.png\" width=\"300px\" style=\"float: left; padding: 5px 0 10px 0\" />\n",
    "\n",
    "<p style=\"padding: 20px 0 0 0\">\n",
    "scikit-learn is an active community project that provides \"off-the-shelf\" ML tools for classical techniques like like Support Vector Machines (SVMs), random forests, k-Means, etc.\n",
    "</p>\n",
    "\n",
    "<br style=\"clear:both\" />\n",
    "\n",
    "<img src=\"../images/tensorflow-logo.png\" width=\"300px\" style=\"float: left; padding: 0px 0 10px 0\" />\n",
    "\n",
    "<p style=\"padding: 30px 0 0 0\">\n",
    "TensorFlow is Google's creation for low-level algorithm design for ML. It is generally meant for more advanced ML programmers who want to create algorithms.\n",
    "</p>\n",
    "\n",
    "<br style=\"clear:both\" />\n",
    "\n",
    "<img src=\"../images/keras-logo.png\" width=\"300px\" style=\"float: left; padding: 5px 0 10px 0\" />\n",
    "\n",
    "<p style=\"padding: 15px 0 0 0\">\n",
    "Keras is another active community creation that focuses on deep learning (neural networks). It can be configured to use various low-level ML APIs, but perhaps it is most frequently paired with TensorFlow as the driving underlying engine.\n",
    "</p>\n",
    "\n",
    "<br style=\"clear:both\" />\n",
    "\n",
    "<p style=\"padding: 15px 0 0 0\">\n",
    "    \n",
    "There are many other powerful ML libs for Python like PyTorch, XGBoost, Theano, CNTK, etc.\n",
    "\n",
    "For the rest of this course, we will use scikit-learn and keras to help us understand the use of various key ML techniques.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 1: Predicting Boston Housing Prices\n",
    "Here we will introduce the basic steps needed to apply ML to a data-centric problem. Assuming you have existing data to grab from, there are 5 steps:\n",
    "1. Load & prep data\n",
    "2. Split data into **train** & **test** data\n",
    "3. Fit the **train** data with the chosen ML **model**\n",
    "4. Find **predict**ions from the **test** data\n",
    "5. Analyze prediction performance\n",
    "(tweak, rinse & repeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Load & prep data\n",
    "We now have the necessary foundation to load and prep all sorts of data (we may still need some help from Google of course).\n",
    "\n",
    "In this case study exercise, we will work with the Boston Housing Dataset from sklearn.\n",
    "\n",
    "Let's start by loading the raw dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the sample dataset lib from sklearn\n",
    "from sklearn import datasets\n",
    "\n",
    "# load data directly from sklearn sample datasets\n",
    "# dataset is an sklearn custom type\n",
    "dataset = datasets.load_boston()\n",
    "print('The datasets from sklearn are formatted as the type', type(dataset))\n",
    "\n",
    "# let's see what this object gives us\n",
    "print('\\nThe info I can get from this Bunch object are:',dataset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXERCISE: Explore the data by completing the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: print the number of (rows, cols) in the input data matrix (the X variable)\n",
    "\n",
    "# TODO: print the number of rows in the output targets (the y variable)\n",
    "\n",
    "# TODO: print the feature names and their descriptions\n",
    "\n",
    "# TODO: print the data DESCRiption to see what the feature names are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert the Bunch type to a pandas DataFrame type, so that it is much easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# construct the df and use the feature_names as the col names\n",
    "df = pd.DataFrame(dataset.data, columns = dataset.feature_names)\n",
    "\n",
    "# add a last col to the df as the output\n",
    "df['PRICE'] = dataset.target\n",
    "\n",
    "# see if everything looks correct\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Split data into Train & Test data\n",
    "With the finite data we have, we need to (1) reserve a large portion for training the chosen ML model, as well as (2) keep a small portion for testing how well the model works. A 75% : 25% split for train:test samples is probably a good rule of thumb.\n",
    "\n",
    "#### EXERCISE: complete the following code to split our df from above, into training and testing datasets. We want to achieve a 75% : 25% split as mentioned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary function to split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: use train_test_split function to obtain 4 datasets:\n",
    "# - X_train : input training data\n",
    "# - X_test  : input test data\n",
    "# - y_train : output training data\n",
    "# - y_test  : output test data\n",
    "# Q: why is X in caps and y in small letters?\n",
    "\n",
    "# TODO: print the shapes of all the outputs to check we have done it correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Fit the Train data into the chosen ML model\n",
    "Here we'll train the ML model, a.k.a model fitting. For simplicity let's choose a linear regression model.\n",
    "\n",
    "#### EXERCISE: complete the following code to initialize a pre-made linear regression model and train it with our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import the pre-made model structures from sklearn\n",
    "from sklearn import linear_model\n",
    "\n",
    "# TODO: create a LinearRegression model object for us to work with\n",
    "# hint: use linear_model.___\n",
    "\n",
    "# TODO: train the model by fitting it onto X_train & y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Find predictions from the Test data\n",
    "With the trained model, we can make predictions with it. We will first test it with the items from our test portion of our data.\n",
    "\n",
    "#### EXERCISE: complete the following code to use the model to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use the trained model to predict outputs from X_test\n",
    "# hint: it is just a one liner with one function call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Analyze prediction accuracy\n",
    "The last step is to analyze how well the model has performed.\n",
    "\n",
    "#### EXERCISE: complete the code below to  calculate the root mean squared error of your predictions\n",
    "#### STRETCH GOAL: plot the predicted values against the expected test values to view the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary modules and functions\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt # for plotting only\n",
    "\n",
    "# TODO: calculate the RMSE\n",
    "# hint: numpy has the square root function\n",
    "\n",
    "# TODO: plot a scatter to visually compare test vs predicted outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
